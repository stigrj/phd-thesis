%TODO Discuss chemical accuracy in relation to HF and KS approximations as well as basis sets
%TODO Mention DFAs at the end of exchange-correlation subsection
%TODO AOs ideal for fast qualitative numbers, struggle with high-accuracy calculations
\chapter{Electronic structure theory}\label{chap:chemistry}
In this chapter we present the equations that govern chemical systems, in particular
the electronic stucture of atoms and molecules. At the molecular length scale, nature
is most accurately described by the theory of quantum mechanics, where the central
problem is the solution of the non-relativistic Schr\"{o}dinger equation.

Being that this problem cannot be solved exactly by any analytical method whenever
the system contains more than two particles, much of the work in the field of quantum
chemistry has been concerned with developing accurate and efficient approximations,
a work that has been given invaluable support by the remarkable increase in 
computational power that has taken place since the advent of the electronic computer 
more than halv a century ago.

This chapter will give an introduction to the self-consistent field (SCF) approximations 
that are commonly employed in computational chemistry. We will start with a traditional 
presentation of the orbital based methods of Hartree-Fock and Kohn-Sham density functional 
theory, where the aim of the chapter is to rewrite the equations into their less familiar 
integral form. An optimization algorithm using the mathematical tools as implemented in 
chapter \ref{chap:implementation} is demonstrated for simple one-electron systems, while 
the treatment of general many-electron systems is the topic of publication III.

Most of the exposition follows that of the standard textbooks of computational chemistry, 
like Szabo and Ostlund\cite{Szabo-Ostlund:1982}, Parr and Yang\cite{Parr-Yang:1989} and 
Jensen\cite{Jensen:2007}, as well as the thesis of Losilla\cite{Losilla_thesis:2013}.

\section{The electronic Schr\"{o}dinger equation}\label{sec:schrodinger}
The physical state of a quantum system influenced by potentials that do not change
with time is described by the time-independent Schr\"{o}dinger equation 
\begin{equation}
    \label{eq:mol_schr}
    \hat{H}\Wavefunction = E\Wavefunction
\end{equation}
where the Hamiltonian $\hat{H}$ is the operator for the total energy $E$ of the system.
The wave function \Wavefunction\ is an eigenfunction of the Hamiltonian operator, 
and is a multi-dimensional (in general complex-valued) function that depends on the 
degrees of freedom of the system, e.i. the position $\bs{r}$ and spin $s$ of all $N$ 
particles, and we have $\Wavefunction=\Wavefunction(\bs{x}_1,\bs{x}_2,\dots,\bs{x}_N)$, 
where $\bs{x}_i=(\bs{r}_i,s_i)$ denotes the position and spin of the $i$-th particle. 
There are in general infinitely many eigenfunctions for a given Hamiltonian operator,
each corresponding to a possible state. 

The wave function contains all the information that can possibly be extracted from the 
physical system. For each physical observable $\Omega$ there is an associated mathematical 
operator $\hat{\Omega}$, such that the expectation value of an experimental measurement is 
given by
\begin{equation}
    \langle \hat{\Omega}\rangle = \frac{\langle\Wavefunction|\hat{\Omega}|\Wavefunction\rangle}
    {\langle\Wavefunction|\Wavefunction\rangle}
\end{equation}
This means that the fundamental problem in quantum chemistry is to obtain the molecular
wave function by solving the Schr\"{o}dinger equation (\ref{eq:mol_schr}). For a molecule,
the Hamiltonian contains kinetic $\hat{T}$ and potential $\hat{V}$ energy of the 
electrons and nuclei that make up the system
\begin{equation}
    \hat{H} = \hat{T}_{nuc} + \hat{T}_{el} + \hat{V}_{nn} + \hat{V}_{ee} + \hat{V}_{ne}
\end{equation}
Analytical solutions exists only for the one- and two-particle problems, and approximations 
are inevitable if we want to be able to treat more interresting chemical systems. 

The first approximation for molecular systems is almost exclusively the Born-Oppenheimer 
approximation\cite{Born-Oppenheimer:1927}, in which we consider the nuclei to be fixed in space, 
so that the electrons move in a static nuclear potential. The motivation behind this 
approximation is that the nuclei are much heavier than the electrons, and hence move much 
slower, so that at the electronic time scale, the nuclei are percieved as classical particles 
frozen in space. This means that we can disregard the instantaneous correlation between the 
electrons and the nuclei, and we can separate the nuclear kinetic energy from an electronic 
Hamiltonian
\begin{align}
    \hat{H} &= \hat{T}_{nuc} + \hat{H}_{el}\\
    \hat{H}_{el} &= \hat{T}_{el} + \hat{V}_{ne} + \hat{V}_{ee} + \hat{V}_{nn}
\end{align}
In atomic units\footnote{$e=m_e=\hbar=4\pi\epsilon_0=1$}, using uppercase indices for the
nuclei and lowercase indices for the electrons, we have the electron kinetic energy
\begin{equation}
    \hat{T}_{el} = -\sum_i \frac{1}{2}\nabla_i^2
\end{equation}
the electron-nuclear attraction
\begin{equation}
    \hat{V}_{ne} = -\sum_{i,I} \frac{Z_I}{\|\bs{r}_i-\bs{R_I}\|}
\end{equation}
the electron-electron repulsion
\begin{equation}
    \hat{V}_{ee} = \sum_{i>j} \frac{1}{\|\bs{r}_j-\bs{r}_i\|}
\end{equation}
and finally the nuclear-nuclear repulsion
\begin{equation}
    \hat{V}_{nn} = \sum_{I>J} \frac{Z_IZ_J}{\|\bs{R}_I-\bs{R_J}\|}
\end{equation}
Within the Born-Oppenheimer approximation, the last term is a simple additive constant 
and is usually left out when solving the electronic problem
\begin{equation}
    \label{eq:el_schr}
    \hat{H}_{el}\wavefunction_{el} = E_{el}\wavefunction_{el}
\end{equation}
At the nuclear time scale, the electrons are percieved as a diffuse charge density that is
able to respond instantaneously to the movement of the nuclei, and molecular rotations and 
vibrations are described by the nuclear wave function which is influenced by this dynamic
electron density. In the following, however, we are concerned exclusively with the calculation 
of the electronic wave function through Eq.~(\ref{eq:el_schr}), where the $el$ subscript 
henceforth will be dropped.

The particular state $\wavefunction_0$ with the lowest energy $E_0$ is called 
the electronic ground state of the system and serves special attention in quantum chemistry.
The reason for this is that for most chemical systems the ground state is the only state
significantly populated under normal laboratory conditions, and hence, most chemical 
phenomena can be explained in terms of properties of the electronic ground state. The way to
calculate the ground state is usually to exploit the variational principle, which states that
for a given Hamiltonian $\hat{H}$ with true ground state $\wavefunction_0$, we have for an arbitrary
trial wave function $\tilde{\wavefunction}$
\begin{equation}
    \label{eq:var_princ}
    \frac{\langle\tilde{\wavefunction}|\hat{H}|\tilde{\wavefunction}\rangle}
    {\langle\tilde{\wavefunction}|\tilde{\wavefunction}\rangle}
    \geq
    \frac{\langle\wavefunction_0|\hat{H}|\wavefunction_0\rangle}
    {\langle\wavefunction_0|\wavefunction_0\rangle}
\end{equation}
which means that finding the ground state can be regarded as a minimization problem, where
the trial wave function is varied to the point where the corresponding energy is minimized.

\section{Hartree-Fock Theory}\label{sec:HFT}
The most apparent complication in developing approximate methods for the solution of the 
electronic Sch\"{o}dinger equation is perhaps the high dimensionality of the problem. For
a system containing $N$ electrons, the wave function is a $3N$-dimensional scalar function 
(disregarding spin). The common way to approach such high-dimensional problems is by
approximating the full $d$-dimensional function in terms of products of functions of lower 
dimensionality. In chemistry it is convenient to use one-particle functions $\orbital_i$, 
called spin-orbitals, which depend on the coordinates of a single electron
\begin{equation}
    \label{eq:orb_exp}
    \wavefunction(\bs{x}_1,\bs{x}_2,\dots,\bs{x}_N) = \sum_m c_m 
	\orbital_1^m(\bs{x}_1)
	\orbital_2^m(\bs{x}_2)\cdots
	\orbital_N^m(\bs{x}_N)
\end{equation}
Unfortunately, the convergence of such expansions is not very good, and a large number
of terms is usually required in order to obtain high accuracy (chemical accuracy is usually
defined as 1 kcal/mol). One way of improving the convergence is to include two-particle 
functions in the expansion. Such approaches, known as 
\emph{explicitly correlated methods}\cite{Rychlewski:2003,Kong:2012}, will not be discussed
in this thesis, and in the following we use wave functions constructed using one-particle 
functions in the form of a Slater determinant.

\subsection{Slater determinant}
Being fermionic, the electronic wave function needs to be anti-symmetric with respect to 
the exchange of two particles
\begin{equation}
    \wavefunction(\bs{x}_1,\bs{x}_2,\bs{x}_3,\dots,\bs{x}_N) = -
    \wavefunction(\bs{x}_2,\bs{x}_1,\bs{x}_3\dots,\bs{x}_N)
\end{equation}
This condition is known as the Pauli exclusion principle\cite{Pauli:1925}, which has the 
consequence that each fermionic state can only be occupied by one particle. The simplest way
of constructing a wave function that fulfills the anti-symmetry requirement using one-particle
spin-orbitals is the Slater determinant\cite{Slater:1929}
\begin{equation}
    \begin{split}
    \wavefunction = |\orbital_1\orbital_2\cdots\orbital_N\rangle \mydef \frac{1}{\sqrt{N!}} 
    \left|
    \begin{array}{cccc}
	\orbital_1(\bs{x}_1)	& \orbital_1(\bs{x}_2)	& \cdots & \orbital_1(\bs{x}_N)\\
	\orbital_2(\bs{x}_1)	& \orbital_2(\bs{x}_2)	& \cdots & \orbital_2(\bs{x}_N)\\
	\vdots			& \vdots		& \ddots & \vdots\\
	\orbital_N(\bs{x}_1)	& \orbital_N(\bs{x}_2)	& \cdots & \orbital_N(\bs{x}_N)
    \end{array}
    \right|
    \end{split}
\end{equation}
where the spin-orbitals $\orbital_i(\bs{x})$ are orthonormal and can be expressed as a product 
of a three-dimensional spatial part and a spin part. The energy of such a wave function is 
evaluated as the expectation value of the Hamiltonian
\begin{align}
    E[\wavefunction] 
	&= \langle\orbital_1\orbital_2\cdots\orbital_N|\hat{H}|
	\orbital_1\orbital_2\cdots\orbital_N\rangle\\
    \label{eq:det_energy}
	&= \sum_{i=1}^N \langle \orbital_i |\hat{h}| \orbital_i \rangle +
	\frac{1}{2} \sum_{i=1}^N \sum_{j=1}^N
	\langle \orbital_i |\hat{J}_j-\hat{K}_j| \orbital_i\rangle
\end{align}
where we have defined the one-electron operator
\begin{equation}
    \hat{h}\orbital_i(\bs{x}) = \bigg(-\frac{1}{2}\nabla^2 - \sum_I\frac{Z_I}{\|\bs{r}-\bs{R}_I\|}\bigg)
	\orbital_i(\bs{x})
\end{equation}
as well as the Coulomb $\hat{J}_j$ and exchange $\hat{K}_j$ operators
\begin{align}
    \hat{J}_j \orbital_i(\bs{x}) &= \bigg(\int \frac{\orbital_j^{\ast}(\bs{x}')\orbital_j(\bs{x}')}
	{\|\bs{r}-\bs{r}'\|}\ud\bs{x}'\bigg) \orbital_i(\bs{x})\\
    \hat{K}_j \orbital_i(\bs{x}) &= \bigg(\int \frac{\orbital_j^{\ast}(\bs{x}')\orbital_i(\bs{x}')}
	{\|\bs{r}-\bs{r}'\|}\ud\bs{x}'\bigg) \orbital_j(\bs{x})
\end{align}
where it is important to note that the integration is over space \emph{and} spin coordinates,
which means that the exchange operator is zero if the spin of orbitals $i$ and $j$ differ. 
The Coulomb operator, on the other hand, in non-vanishing for all pairs of spin-orbitals.

\subsection{The Hartree-Fock equations}
The best approximation to the ground state in terms of a \emph{single} Slater determinant is 
called the Hartree-Fock wave function, and is obtained by minimizing the energy with respect 
to orbital variations
\begin{equation}
    E_0 = \mymin{\wavefunction}\ E[\wavefunction]
\end{equation}
following the variational principle of Eq.~(\ref{eq:var_princ}). 
In the following we will assume that we have a closed-shell system, so that the $N$ electrons
are grouped into $N/2$ pairs sharing the same spatial function, but with opposite spins
\begin{equation}
    \orbital_i^\sigma(\bs{x}) = \orbital_i(\bs{r})\sigma(s), \qquad \sigma = \alpha,\beta
\end{equation}
By imposing the constraint that the spatial orbitals remain orthonormal 
$\langle\orbital_i|\orbital_j\rangle = \delta_{ij}$
by means of Lagrange multipliers, the energy minimization yields the Hartree-Fock equations
\begin{equation}
    \hat{F}\orbital_i(\bs{r}) = \epsilon_i \orbital_i(\bs{r})
\end{equation}
where the Fock operator is given as
\begin{equation}
    \hat{F} = \hat{h} + \sum_j^{N/2} \Big(2\hat{J}_j - \hat{K}_j\Big)
\end{equation}
The (restricted) Hartree-Fock wave function is then obtained as the Slater determinant 
constructed by the $N/2$ lowest energy eigenfunctions $\orbital_i$ of the Fock operator, 
each appearing twice with paired spins
\begin{equation}
    \wavefunction = |\orbital_1^\alpha\orbital_1^\beta\cdots
	    \orbital_{N/2}^\alpha\orbital_{N/2}^\beta\rangle
\end{equation}
Some of the terms included in the Fock operator can be expressed as multiplicative
potentials instead of operators. The core Hamiltonian $\hat{h}$ includes the scalar 
electrostatic potential arising from the nuclear charges
\begin{equation}
    \label{eq:nuc_pot}
    v_{nuc}(\bs{r}) = \sum_{I} \frac{Z_I}{\|\bs{r} - \bs{R}_I\|}
\end{equation}
and the sum of the Coulomb operators is the potential arising from all electrons of the system
\begin{equation}
    v_{el}(\bs{r}) = \sum_j^{N/2} 2\hat{J}_j = 2 \sum_j^{N/2} \int \frac{|\orbital_j(\bs{r}')|^2}
	{\|\bs{r} - \bs{r}'\|} \ud \bs{r}'
\end{equation}
If we further collect the exchange operators into a single operator
\begin{equation}
    \label{eq:HF_exchange}
    \hat{K}\orbital_i(\bs{r}) = \sum_j^{N/2} \hat{K}_j \orbital_i(\bs{r}) 
	= \sum_j^{N/2} \orbital_j (\bs{r}) \int \frac{\orbital_j^{\ast}(\bs{r}')\orbital_i(\bs{r}')}
	    {\|\bs{r} - \bs{r}'\|} \ud \bs{r}'
\end{equation}
we can write the Hartree-Fock equations as
\begin{equation}
    \label{eq:HF_equations}
    \Big[-\frac{1}{2}\nabla^2 + v_{nuc}(\bs{r}) + v_{el}(\bs{r}) - \hat{K}\Big]\orbital_i(\bs{r}) 
	= \epsilon_i \orbital_i(\bs{r})
\end{equation}
As both the electronic potential $v_{el}$ and the exchange operator $\hat{K}$ depend on the 
set of occupied orbitals, we have a set of coupled non-linear differential equations that need 
to be solved iteratively until we reach a self-consistent solution. 

The main deficiancy of such a self-consistent field (SCF) approximation is that each electron 
only interacts with the average field created by the other electrons. While this is a good 
approximation for the electron's interaction with the slow moving nuclei, the instantaneous 
correlation is more important between two electrons. The Hartree-Fock method still provides 
a reasonable qualitative description of molecules near their equilibrium geometry, capturing 
95-99\% of the total energy.  This, however, is generally not sufficient to reach chemical 
accuracy, and there exists several post-Hartree-Fock methods that model the missing 
\emph{correlation} energy, including configuration interaction (CI) and coupled-cluster (CC)
theory, but these will not be discussed 
(see e.g.\cite{Szabo-Ostlund:1982,Jensen:2007,Helgaker:2000}).

\section{Density Functional Theory} \label{sec:DFT}
We have seen that the main computational challenge in solving the Schr\"{o}dinger equation is 
its high dimensionality, and that by introducing one-particle orbitals the $3N$-dimensional 
differential equation can be separated into $N$ ($N/2$ for a closed-shell system) coupled 
three-dimensional equations. Hohenberg and Kohn\cite{Hohenberg-Kohn:1964} showed that the 
complexity can be reduced even further by proving that the only quantity that is really
needed in order to determine the system uniquely is the three-dimensional electron density
\begin{equation}
    \rho(\bs{r}_1) = N \int |\wavefunction(\bs{x}_1,\bs{x}_2,\dots,\bs{x}_N)|^2 
	\ud s_1 \ud \bs{x}_2 \cdots \ud \bs{x}_N
\end{equation}
and that the true energy of the system can be expressed in terms of a universal energy functional
\begin{equation}
    E[\rho] = T[\rho] + V_{ne}[\rho] + V_{ee}[\rho]
\end{equation}
where the ground state density can be obtained by minimizing the energy
\begin{equation}
    E_0 = \mymin{\rho}\ E[\rho]
\end{equation}
with the constraints that the density is everywhere positive and integrates to the number
of electrons. Within the Born-Oppenheimer approximation the electron-nuclear interaction
energy is known as the classical electrostatic energy between charge densities
\begin{equation}
    V_{ne}[\rho] = \int \rho(\bs{r})v_{nuc}(\bs{r}) \ud \bs{r}
\end{equation}
with the nuclear potential defined through Eq.~(\ref{eq:nuc_pot}), but the functional form of 
the kinetic and electron-electron energies are not known for quantum mechanical densities 
(as we have seen in the previous section, the quantum mechanical interaction between electrons 
includes both exchange and correlation energy, in addition to the classical electrostatic 
interaction), and the fundamental problem in density functional theory (DFT) is to find good 
approximations for these energy functionals, either based on theoretical considerations, or 
semi-empirically by fitting parameters to experimental data.

\subsection{The Kohn-Sham equations}
The general idea of DFT appears very appealing, as we only need to solve one three-dimensional 
equation for the electron density. However, it turns out to be very difficult to find good 
approximations for the kinetic energy functional, and according to the virial theorem this 
energy is of the order of the total energy of the system, and thus needs to be accurately 
represented. To circumvent this problem, Kohn and Sham\cite{Kohn-Sham:1965} proposed to express 
the density in terms of one-particle functions, which for a closed shell system with double 
occupancy yields
\begin{equation}
    \rho(\bs{r}) = 2 \sum_i^{N/2} | \orbital_i(\bs{r})|^2
\end{equation}
thus reintroducing the orbital notion of Hartree-Fock theory. The motivation behind this is 
that the kinetic energy is known for a set of (non-interacting) orbitals as
\begin{equation}
    T_s[\rho] = 2 \sum_i^{N/2} \langle \orbital_i | -\frac{1}{2}\nabla^2 | \orbital_i \rangle
\end{equation}
However, this is not equal to the real kinetic energy of the (interacting) system, and we are 
missing a small part of the total energy $T[\rho] - T_s[\rho]$. We can similarly extract the 
known classical part from the density's interaction with itself
\begin{equation}
    J[\rho] = \frac{1}{2}\int\int\frac{\rho(\bs{r})\rho(\bs{r}')}{\|\bs{r}-\bs{r}'\|} \ud\bs{r}\ud\bs{r}' 
	= \frac{1}{2} \int \rho(\bs{r})v_{el}(\bs{r}) \ud \bs{r}
\end{equation}
where again we are missing a small part of the total energy $V_{ee}[\rho] - J[\rho]$. The custom 
in Kohn-Sham theory is then to collect the missing parts into a single exchange-correlation 
functional
\begin{equation}
    E_{xc}[\rho] = T[\rho] - T_s[\rho] + V_{ee}[\rho] - J[\rho]
\end{equation}
and we get the total Kohn-Sham energy expressed as
\begin{equation}
    \label{eq:KS-energy}
    E[\rho] = T_s[\rho] + V_{en}[\rho] + J[\rho] + E_{xc}[\rho]
\end{equation}
Minimizing the energy with respect to the density leads to the Euler equation
\begin{equation}
    \label{eq:KS-euler}
    \mu = \frac{\delta T_s[\rho]}{\delta \rho(\bs{r})} + v_{eff}(\bs{r})
\end{equation}
where the chemical potential $\mu$ is a Lagrange multiplier that fixes the number of 
electrons, and the effective potential is given in terms of functional derivatives
\begin{align}
    v_{eff}(\bs{r}) 
	&= \frac{\delta V_{en}[\rho]}{\delta \rho(\bs{r})}
	+ \frac{\delta J[\rho]}{\delta \rho(\bs{r})}
	+ \frac{\delta E_{xc}[\rho]}{\delta \rho(\bs{r})}\\
	\label{eq:effective_pot}
	&= v_{nuc}(\bs{r}) + v_{el}(\bs{r}) + v_{xc}(\bs{r})
\end{align}
The Euler equation (\ref{eq:KS-euler}) describes a system of non-interacting electrons 
moving in an effective potential $v_{eff}$, and the Hamiltonian for such a system is given 
trivially as
\begin{equation}
    \hat{H} = -\sum_i^{N/2} \frac{1}{2}\nabla_i^2 + \sum_i^{N/2} v_{eff}(\bs{r}_i)
\end{equation}
This operator is separable and the exact wave function is a single determinant constructed 
by the $N/2$ lowest energy eigenfunctions of the Fock (or Kohn-Sham) operator
\begin{equation}
    \hat{F} = -\frac{1}{2}\nabla^2 + v_{eff}(\bs{r})
\end{equation}
each appearing twice with paired spins, and the minimization problem of the DFT Euler equation 
now entails solving the Kohn-Sham equations
\begin{equation}
    \label{eq:KS_equations}
    \Big[-\frac{1}{2}\nabla^2 + v_{nuc}(\bs{r}) + v_{el}(\bs{r}) + v_{xc}(\bs{r})\Big] 
	\orbital_i(\bs{r}) = \epsilon_i \orbital_i(\bs{r})
\end{equation}
We see that by reintroducing orbitals we abandon the hope of expressing the problem in terms 
of a single three-dimensional equation, and again we get a set of $N/2$ coupled non-linear 
equations for the orbitals. As the effective potential in the Kohn-Sham operator depends on 
the density, and thus on the orbitals, Kohn-Sham DFT is also referred to as an SCF method, 
and given the similarity with the Hartree-Fock equations (\ref{eq:HF_equations}), the same 
techniques can be used to solve both problems. 

\subsection{Density functional approximations}
As already mentioned, the exact form of the universal exchange-correlation functional is 
not known, so the quality of any Kohn-Sham calculation is only as good as the quality of
the density functional approximation (DFA) being used. The exchange-correlation energy is 
expressed as an integral over an energy density
\begin{equation}
    E_{xc}[\rho] = \int F_{xc}\ud \bs{r}
\end{equation}
In the local density approximation (LDA) the energy density is a function of the density 
alone $F_{xc}(\rho)$, in the generalized gradient approximation (GGA) it is a function of
the density and its gradient $F_{xc}(\rho, |\nabla\rho|)$, while in meta-GGA's, higher 
order derivatives are introduced $F_{xc}(\rho, |\nabla\rho|, \nabla^2\rho, \cdots)$. 
Hybrid functionals are GGA's with a certain amount of exact Hartree-Fock exchange, 
evaluated as in Eq.~(\ref{eq:HF_exchange}) using Kohn-Sham orbitals. This increasing 
complexity in the DFA will in general yield increasingly accurate results.

The exchange-correlation potential was implicitly defined in Eq.~(\ref{eq:effective_pot}) 
as the functional derivative of the exchange-correlation energy with respect to the density
\begin{equation}
    v_{xc} = \frac{\delta E_{xc}[\rho]}{\delta \rho} 
	= \frac{\delta}{\delta \rho} \int F_{xc} \ud \bs{r}
\end{equation}
which can be calculated for LDAs and GGAs through
\begin{align}
    \label{eq:LDA_pot}
    v_{xc}^{LDA} &= \frac{\partial F_{xc}}{\partial \rho}\\
    \label{eq:GGA_pot}
    v_{xc}^{GGA} &= \frac{\partial F_{xc}}{\partial \rho} - 
	\nabla\cdot\frac{\partial F_{xc}}{\partial\nabla\rho}
\end{align}
A wide range of DFAs are available in the literature, with different costs, accuracies and
ranges of applicability\cite{Burke:2012}.

%\subsection{Spin-unrestricted Kohn-Sham}
%The extension to spin-unrestricted and open-shell systems is straightforward. In this case the
%$\alpha$ and $\beta$ electrons occupy different spatial orbitals, $\orbital^\alpha$ and 
%$\orbital^\beta$, and we define the corresponding spin densities
%\begin{equation}
%    \rho^{\sigma}(\bs{r}) = 
%	\sum_{i=1}^{N_{\sigma}} |\phi_i^{\sigma}(\bs{r})|^2, \qquad \sigma = \alpha, \beta
%\end{equation}
%All spin effects are included in the exchange-correlation potential, which in this case will 
%depend on the spin densities and possibly their gradients, and the $\alpha$ and $\beta$ electrons 
%will experience different effective potentials
%\begin{equation}
%    v_{eff}^{\sigma} (\bs{r}) = 
%	v_{nuc}(\bs{r}) + v_{el}(\bs{r}) + v_{xc}^{\sigma}(\bs{r}), \qquad \sigma = \alpha, \beta
%\end{equation}
%The nuclear potential is the same as before, whereas the electronic potential is obtained
%from the total electron density
%\begin{equation}
%    v_{el}(\bs{r}) = \int \frac{\rho^\alpha(\bs{r}') + \rho^\beta(\bs{r}')}
%	{\|\bs{r}-\bs{r}'\|} \ud \bs{r}'
%\end{equation}
%This leads to different Kohn-Sham operators for the different spins
%\begin{equation}
%    \hat{F}_{KS}^\sigma = -\sum_i^{N_\sigma} \frac{1}{2}\nabla_i^2 + 
%	\sum_i^{N_\sigma} v_{eff}^\sigma(\bs{r}_i), \qquad \sigma = \alpha, \beta
%\end{equation}
%and a single determinant wave function is constructed by the $N_\alpha$ and $N_\beta$ 
%lowest energy eigenfunctions of the operators $\hat{F}_{KS}^\alpha$ and 
%$\hat{F}_{KS}^\beta$, respectively.

\section{Basis sets in computational chemistry}
Even with the approximations presented in the previous sections, the SCF equations are still
to complicated to be solved analytically for many-electron systems, and we rely on numerical
solution algorithms in order to make the theoretical methods useful. As computers work in finite
arithmetic using floating point numbers of finite accuracy, we need to discretize the problem 
in one way or another. This can be done either by representing functions as a collection of
point values on a grid with some kind of regularity, where for instance differential operators
can be defined through finite differences, or by expanding the solution in terms of a set of 
basis functions $\AO_p$
\begin{equation}
    \label{eq:basis_exp}
    f(\bs{r}) = \sum_p^\infty c_p \AO_p(\bs{r}) \approx \sum_p^N c_p \AO_p(\bs{r})
\end{equation}
The equality in Eq.~(\ref{eq:basis_exp}) holds for any function $f$ if the basis set is complete,
but this usually requires an infinite expansion. In practice, the expansion is truncated at some 
point, yielding an approximation of the given function, and the problem has been discretized to 
a finite number of expansion coefficients $c_p$. 

In principle any set of linearly independent functions can be used as a basis, but there are
certain properties that we want from the basis for it to be computationally 
attractive\cite{Losilla_thesis:2013}
\begin{itemize}
    \item \bs{Accuracy}\\
	The basis set must be able to represent the target functions faithfully, and provide
	results that are sufficiently accurate for a given purpose.
    \item \bs{Compactness}\\
	For a given accuracy, the size of the basis set should be as small as possible.
    \item \bs{Efficiency}\\
	The mathematical operations that involve the basis functions should be performed as 
	fast as possible.
    \item \bs{Systematicity}\\
	The basis set should depend on a set of parameters that can be modified such that the 
	accuracy of a given calculation will improve.
    \item \bs{Universality}\\
	The performance, in terms of accuracy and efficiency, should be adequate to model a large 
	variety of properties and systems.
\end{itemize}
It turns out that no basis can give you all these properties at once, so we have to make some 
kind of compromise when choosing a basis set for a certain problem, and the choice will often 
depend on known analytical properties of the solution. 

For instance, it is known that the ground state wave function is continous, but not differentiable 
at the nuclear positions\cite{Kato:1957}.
Similar \emph{cusps} appear in the wave function when the coordinate of two electrons coincide, 
as well as for the molecular orbitals and the electron density at the nuclear positions. 
Specifically, the behavior of the density close to a nucleus is known to be
\begin{equation}
    \rho(\bs{r}) \sim e^{-2Z_J|\bs{r}-\bs{R}_J|}, \qquad |\bs{r}-\bs{R}_J| \ll 1
\end{equation}
while it decays exponentially at long distances 
\begin{equation}
    \rho(\bs{r}) \sim e^{-2\sqrt{2E_I}|\bs{r}-\bs{R}_J|}, \qquad |\bs{r} - \bs{R}_J| \gg 1
\end{equation}
where $E_I$ is the ionization potential. Similar conditions apply for the molecular orbitals.

\subsection{Atom-centered basis functions}
It is desireable to use basis functions with the same asymptotic behavior as the density in order 
to get efficient representations, e.i. localized functions centered at the nuclear positions, with 
a short range cusp and an exponential tail. Furthermore, the chemical notion of a molecule being 
a collection of atoms suggests that a reasonable approach would be to express the molecular orbitals 
(MOs) as linear combinations of atomic orbitals (LCAO)
\begin{equation}
    \orbital_i(\bs{r}) = \sum_I\sum_p^{M_I} c_{ip}\AO_p(\bs{r}-\bs{R}_I) 
\end{equation}
where the atomic orbitals (AOs) are atom-centered functions similar to the eigenfunctions of the 
hydrogen atom. Even if the presence of several nuclei in a molecule breaks the angular symmetry
around each atom, the nuclear potential is so steep that the symmetry is to a large extent retained
in the vicinity of the nucleus. The AOs are thus chosen to be spherically symmetric functions that 
can be separated into an angular part, in the form of spherical harmonics $Y_{lm}(\theta,\varphi)$, 
and a radial part $R(r)$
\begin{equation}
    \AO_p (\bs{r}) = R_p(r)Y_{l_p,m_p}(\theta,\varphi)
\end{equation}
This basis can approach completeness either in the angular part, by increasing the maximum angular 
momentum $L$ in the spherical harmonics, or in the radial part by adding more linearly independent
radial functions. It is well established that the convergence in the angular part is exponential
($\sim e^{-\sqrt{L}}$) for Hartree-Fock energies (for post-Hartree-Fock methods the convergence is 
slower $\sim L^{-3}$), which means that very large $L$ is typically not needed for SCF calculations. 

By choosing exponential radial functions
\begin{equation}
    R_p^{STO}(r) = N_pr^{n_p}e^{-\xi_p r}
\end{equation}
we get the so-called Slater type orbitals (STO)\cite{Slater:1930}, which have the 
correct asymptotic behavior. This
means that the basis is rather efficient for describing molecular orbitals and densities, leading
to compact representations and fairly rapid basis set convergence also for the radial part.
The main problem, however, with STOs is numerical efficiency. In Hartree-Fock calculations the
main bottleneck is the evaluation of three- and four-center two-electron integrals in the form
\begin{equation}
    g_{pqrs} = \int\int \AO_p(\bs{r}_1)\AO_q(\bs{r}_1)\frac{1}{\|\bs{r}_1-\bs{r}_2\|}
	\AO_r(\bs{r}_2)\AO_s(\bs{r}_2) \ud\bs{r}_1\ud\bs{r}_2
\end{equation}
for which there exist no analytic formula in the case of STOs. For this reason, the main
applications for the STO basis is for small systems (atoms and diatomics) where high accuracy
is required, or for density functional methods that do not include exact exchange, and where 
the Coulomb energy is calculated using an auxiliary basis.

The computational efficiency of the evaluation of two-electron integrals can be dramatically 
improved by choosing Gaussian type orbitals (GTOs)\cite{Boys:1950}, where the radial 
functions have the form
\begin{equation}
    R_p^{GTO}(r) = N_pr^{n_p}e^{-\xi_p r^2}
\end{equation}
In this case the integrals can be calculated analytically, however, the $r^2$ dependence in the 
exponential makes the GTOs inferior to the STOs in describing molecular orbitals and densities,
as they do not have the correct asymptotic behavior: at the nucleus the GTO has zero slope instead
of a cusp, and it falls off too rapidly at long distances. This means that much larger basis sets
are required for a given accuacy, but this is more than compensated for in terms of computational
efficiency by the ease of which the required integrals can be calculated. Furthermore, by using
contracted GTOs, where each basis function can contain several primitive Gaussians
\begin{equation}
    R_p^{cGTO}(r) = r^{n_p}\sum_ja_{pj}e^{-\xi_{pj} r^2}
\end{equation}
where the coefficients $a_{pj}$ are kept fixed, we can to a large degree compensate for the incorrect
asymptotic behavior, while keeping the number of variational parameters that need to be optimized as
low as possible. The computational efficiency of the cGTO bases have made them by far the most
popular choice in computational chemistry. The parameters (contraction coefficients and exponents)
of the basis are preoptimized, usually based on atomic calculations, and there are several basis
set families that are systematized in sequences of increasing accuracy (and consequently 
increasing computational cost). 

A rigorous systematicity, however, holds only for smaller systems in the lower-quality end of the basis
set ladder. When the number of basis functions grows, the basis sets become overcomplete, and linear
dependencies appear, leading to numerical instabilities, poorly conditioned equations and poor
convergence of iterative methods. This also affects the minimum error attainable, making it difficult 
to approach the basis set limit for a given level of theory.

Another problem of atom-centered basis sets is their lack of universality. The preoptimization of the
parameters biases the results towards a particular property, making it difficult to judge the quality 
of the calculation of other properties.

\subsection{Plane wave basis functions}
Rather than using localized AO-like basis functions that are trying to model each atom separately,
and forming molecular orbitals through LCAOs, one can start with basis functions that are aimed directly
at the full system. This approach is most appropriate for modelling infinite systems represented by
a unit cell with periodic boundary conditions, such as metals where the valence electrons are delocalized
and thus well represented by solutions of the free electron Sch\"{o}dinger equation. The three-dimensional 
plane wave basis is usually written in terms of complex exponentials
\begin{equation}
    \AO_p(\bs{r}) = e^{i\bs{k}_p\cdot\bs{r}}
\end{equation}
where the wave vector $\bs{k}$ gives the oscillation frequency and is related to the energy of the basis
function. The size of the basis is determined by the sampling resolution in $k$-space (spacing between 
$k$-vectors) and the highest energy $\bs{k}$-vector included, which depend on the size of the unit cell,
and is usually significantly larger than the size of typical Gaussian basis sets. 

Plane waves can in principle be used
for non-periodic systems as well, by placing the molecule in a sufficiently large unit cell where its 
interaction with its own image in the neighboring cells can be neglected. However, placing a small
molecule in a large unit cell requires disproportionally many basis functions, and the molecule is 
represented much more efficiently using localized atomic orbitals.

The plane wave basis is also ill-suited to represent the core region of atoms, where many rapidly 
oscillating functions are required, and especially the singularity in the nuclear potential, which 
is almost impossible to describe in this basis. On the other hand, plane waves are ideal for 
representing the smooth density of delocalized valence electrons, and are usually used in connection 
with pseudopotentials, where the effect of the core electrons are combined with the nuclear charges 
to give an \emph{effective core potential}, and only the valence electrons are treated explicitly. 
This, in combination with the fast Fourier transform (FFT), have made plane wave methods the 
preferred choice for the treatment of many-particle problems of condensed phases. 

\subsection{Real-space representations}
Most of the problems connected with atom-centered basis sets are related to their global support,
and these issues can be adressed using numerical real-space methods. In these methods each expansion
coefficient is usually directly related to the function value at a certain grid point in space, and
a systematic improvement of the accuracy is readily obtained by decreasing the spacing between the 
grid points. The finite element (FE) basis is considered a real-space method even if the representations
are given through basis set expansions. The reason for this is that the basis is grouped into a small
number of $n$ functions sharing the same compact support, disjoint from the support of all other basis 
functions, making them responsible for the function representation in a certain region of real space.
The expansion coefficients are usually obtained through numerical quadrature, which means that the $n$
functions are related to $n$ point values. Moreover, using interpolating polynomials each basis function 
is directly connected to a single grid point.

While the FE basis solves the problems of the AO basis concerning systematicity, universality and 
attainable accuracy, it takes a heavy blow when it comes to compactness of the representation. 
Originally, the FE bases required a uniform grid, making them highly inefficient for the treatment of
multiscale problems like the electronic structure of molecules, where high precision requires 
high resolution in the nuclear region. A uniform grid will in this case result in an excessive 
overrepresentation of the much smoother interatomic region, making accurate calculations very 
computationally demanding, even if the fundamental mathematical operations involving the polynomial
basis are very efficient. 

Due to the high cost of real-space methods, applications in electronic structrure calculations are
uncommon, and for a long time they were limited to benchmarking calculations on small systems 
of high symmetry\cite{Laaksonen:1983-1,Laaksonen:1983-2,Laaksonen:1983-3,Kobus:1996}. Some 
attempts have been made to overcome the problem, either by 
removing the high frequency core region by means of pseudopotentials, or by combining the FE basis 
with another basis of AO type with complementary properties that is able to treat the nuclear region 
more efficiently\cite{Kurashige:2007,Watson:2008,Kurashige:2010,Losilla:2012}. Another approach, 
which is the one persued in this work,
that is applicable to all-electron calculations of systems of arbitrary geometries, is based on 
multiresolution analysis and the multiwavelet basis. This approach, that was pioneered by Harrison and 
coworkers\cite{Harrison_basic:2004} some ten years ago, allows for strict error control using adaptive 
non-uniform grids, thus reducing the computational cost significantly.

\section{Integral formulation}
The discretization of the Hartree-Fock (\ref{eq:HF_equations}) and Kohn-Sham (\ref{eq:KS_equations})
equations using the atom-centered basis leads to the Roothaan-Hall\cite{Roothaan:1951,Hall:1951} 
matrix 
equations that are solved iteratively using standard convergence acceleration techniques like
the direct inversion of the iterative subspace (DIIS)\cite{Pulay:1980}. This approach is not 
appropriate
for the FE and multiwavelet bases due to the high number of basis functions involved. Moreover,
in a discontinuous basis, differential operators (especially higher order operators like
the kinetic energy) should be avoided in order to maintain high accuracy\cite{Harrison_basic:2004}.

Following Harrison \etal\cite{Harrison_basic:2004}, we use Kalos'\cite{Kalos:1962} integral 
formulation of the 
Schr\"{o}dinger equation, and in the following we rewrite the Hartree-Fock (\ref{eq:HF_equations}) 
and Kohn-Sham (\ref{eq:KS_equations}) equations into their integral form, using the integral 
convolution operators
\begin{equation}
    g(\bs{r}) = \hat{G}\big[f\big](\bs{r}) \mydef \int G(\bs{r}-\bs{r}') f(\bs{r}') \ud\bs{r}'
\end{equation}
that were presented in chapter \ref{chap:implementation}, where we specifically described
the implementation of the Poisson, the bound-state Helmholtz and the first order derivative 
operators, with respective integral kernels
\begin{align}
    P(\bs{r}-\bs{r}') &= \frac{1}{4\pi\|\bs{r}-\bs{r}'\|}\\
    H^\mu(\bs{r}-\bs{r}') &= \frac{e^{-\mu\|\bs{r}-\bs{r}'\|}}{4\pi\|\bs{r}-\bs{r}'\|}\\
    D(x-x') &= -2\beta \sqrt{\frac{\beta}{\pi}}(x-x')e^{-\beta (x-x')^2}
\end{align}
The Poisson operator $\hat{P}=\big[-\nabla^2\big]^{-1}$ will be used in the calculation of 
electrostatic potentials as well as the Hartree-Fock exchange operator, the Helmholtz 
operator $\hat{H}^\mu=\big[-\nabla^2+\mu^2\big]^{-1}$ appears in the integral formulation 
of the Hartree-Fock and Kohn-Sham equations, and the derivative operator $\hat{D}^x$ is 
needed for the calculation of exchange-correlation potentials using GGA functionals.

\subsection{Hartree-Fock}
In the closed-shell restricted Hartree-Fock model, the electron density is given from
$N/2$ doubly occupied orbitals
\begin{equation}
    \rho(\bs{r}) = \sum_i^{N/2} 2 |\orbital_i(\bs{r})|^2
\end{equation}
The electronic potential is calculated from the electron density by application of the 
Poisson operator
\begin{equation}
    v_{el}(\bs{r}) = \hat{P}\big[\rho\big](\bs{r})
\end{equation}
and we denote the total Coulomb potential experienced by the electrons as
\begin{equation}
    v_{coul}(\bs{r}) = v_{nuc}(\bs{r}) + v_{el}(\bs{r})
\end{equation}
The exchange operator can also be expressed in terms of the Poisson operator
\begin{equation}
    \hat{K}\orbital_i(\bs{r}) = \sum_j^{N/2} \orbital_j(\bs{r}) 
	\hat{P}\big[\orbital_i\orbital_j\big](\bs{r})
\end{equation}
Furthermore, we can rearrange the Hartree-Fock equations so that they can be expressed in 
terms of the Helmholtz operator
\begin{align}
    \Big[-\frac{1}{2}\nabla^2+v_{coul}(\bs{r})+\hat{K}\Big]\orbital_i(\bs{r}) 
	    &= \epsilon_i \orbital_i(\bs{r})\\
    \big[-\nabla^2 - 2\epsilon_i\big]\orbital_i(\bs{r}) 
	    &= -2\Big[\big(v_{coul}(\bs{r})-\hat{K}\big)\orbital_i(\bs{r})\\
    \orbital_i &= -2\hat{H}^{\mu_i}\Big[\big(v_{coul} - \hat{K}\big) \orbital_i\Big]
\end{align}
with $\mu_i = \sqrt{-2\epsilon_i}$. The equations are still implicitly coupled through the 
electronic potential and the exchange operator, and need to be solved self-consistently by 
iterative methods. Note that both the orbitals $\orbital_i$ and their corresponding energy 
$\epsilon_i$ are unknowns in the equations, and must be determined simultaneously.

\subsection{Kohn-Sham DFT}
In the Kohn-Sham equations the exchange operator is replaced by the exchange-correlation 
potential, which for a given functional can be calculated from Eqs.~(\ref{eq:LDA_pot}) and 
(\ref{eq:GGA_pot}) for LDAs and GGAs, respectively, using the gradient operator 
$\nabla=\big(\hat{D}^x,\hat{D}^y,\hat{D}^z\big)$ in case of the latter. Following the same 
procedure as for the Hartree-Fock equations we get $N/2$ separated equations
\begin{align}
    \Big[-\frac{1}{2}\nabla^2+v_{eff}(\bs{r})\Big]\orbital_i(\bs{r}) 
	    &=\epsilon_i \orbital_i(\bs{r})\\
    \orbital_i &= -2\hat{H}^{\mu_i}\Big[v_{eff} \orbital_i \Big] 
\end{align}
where $\mu_i = \sqrt{-2\epsilon_i}$. Again, the equations are coupled through the effective 
potential, and are solved self-consistently with respect to the orbitals and energies.

\subsection{Calculation of energy}
We will now assume that the Hartree-Fock or Kohn-Sham equations have been solved to obtain
the orbitals $\orbital_i$ that make up ground state wave function, as well as their energies 
$\epsilon_i$, and use these to calculate the electronic energy of the molecular system.
Numerical algorithms for how to solve these equations are presented in section 
\ref{sec:algorithms} in the simple case of a one-electron system, and more generally in
publication III for many-electron systems. In addition to the electronic energy we have 
the constant nuclear repulsion energy
\begin{equation}
    \hat{V}_{nn} = \sum_{I>J} \frac{Z_IZ_J}{\|\bs{R}_I-\bs{R}_J\|}
\end{equation}
The goal of this section is to rewrite the expressions given above into something better 
suited for evaluation in the multiwavelet framework. In particular this means to avoid
the application of the kinetic energy operator.

\subsubsection{Hartree-Fock}
The energy of a Slater determinant wave function was given in Eq.~(\ref{eq:det_energy}), 
which can be expressed in the following way, assuming a closed-shell system and doubly
occupied orbitals
\begin{align}
    E	&= \sum_i^{N/2} 2\langle \orbital_i|\hat{h}|\orbital_i \rangle
	    + \frac{1}{2} \sum_i^{N/2} 2\langle \orbital_i|2\hat{J} - \hat{K}|\orbital_i \rangle\\
	&= \sum_i^{N/2} 2\langle \orbital_i|\hat{T}|\orbital_i \rangle
	    + \sum_i^{N/2} 2\langle \orbital_i|v_{nuc}|\orbital_i \rangle
	    + \sum_i^{N/2} \langle \orbital_i|v_{el} - \hat{K}|\orbital_i \rangle \\
    \label{eq:energy_exp_HF}
	&= \sum_i^{N/2} \langle \orbital_i|2\hat{T} - \hat{K}|\orbital_i \rangle
	    + \int \rho(\bs{r})v_{nuc}(\bs{r}) \ud\bs{r}
	    + \frac{1}{2} \int \rho(\bs{r})v_{el}(\bs{r}) \ud\bs{r}
\end{align}
The kinetic energy operator can be avoided by making the following observation
\begin{align}
    \sum_i^{N/2} 2 \epsilon_i 
	&= \sum_i^{N/2} 2\langle\orbital_i|\hat{T}+v_{nuc}+v_{el}-\hat{K}|\orbital_i\rangle\\
    \label{eq:sum_orb_HF}
	&= \sum_i^{N/2} 2\langle\orbital_i|\hat{T} - \hat{K}|\orbital_i\rangle
	    + \int \rho(\bs{r})v_{nuc}(\bs{r}) \ud\bs{r}
	    + \int \rho(\bs{r})v_{el}(\bs{r}) \ud\bs{r}
\end{align}
Comparing the expressions in Eqs.~(\ref{eq:energy_exp_HF}) and (\ref{eq:sum_orb_HF}) we see that
the total electronic energy can be calculated as
\begin{equation}
    E = 2 \sum_i^{N/2} \epsilon_i - \frac{1}{2} \int \rho(\bs{r})v_{el}(\bs{r}) \ud\bs{r}
	- \sum_i^{N/2} \langle\orbital_i|\hat{K}|\orbital_i\rangle
\end{equation}
without the need of applying the kinetic energy operator, given the orbitals and orbital energies
that solves the Hartree-Fock equations.

\subsubsection{Kohn-Sham DFT}
The energy in Kohn-Sham DFT was given through the energy functionals
\begin{equation}
    E[\rho] = T_s[\rho] + V_{en}[\rho] + J[\rho] + E_{xc}[\rho]
\end{equation}
which for a closed-shell system with double occupancy gives
\begin{equation}
    \label{eq:energy_exp_KS}
    E = \sum_i^{N/2} 2\langle \orbital_i|\hat{T}|\orbital_i \rangle
	+ \int \rho(\bs{r})v_{nuc}(\bs{r}) \ud\bs{r}
	+ \frac{1}{2} \int \rho(\bs{r})v_{el}(\bs{r}) \ud\bs{r}
	+ \int F_{xc} \ud\bs{r}
\end{equation}
The sum of orbital energies can be expressed as
\begin{align}
    \sum_i^{N/2} 2\epsilon_i 
	&= \sum_i^{N/2} 2\langle\orbital_i|\hat{T} + v_{eff}|\orbital_i\rangle\\
    \label{eq:sum_orb_KS}
	&= \sum_i^{N/2} 2\langle\orbital_i|\hat{T}|\orbital_i\rangle
	    + \int \rho(\bs{r})\Big[v_{nuc}(\bs{r})+v_{el}(\bs{r})+v_{xc}(\bs{r})\Big] \ud\bs{r}
\end{align}
Combining Eqs.~(\ref{eq:energy_exp_KS}) and (\ref{eq:sum_orb_KS}) gives an expression without
kinetic energy
\begin{equation}
    E = 2 \sum_i^{N/2} \epsilon_i - \frac{1}{2} \int \rho(\bs{r})v_{el}(\bs{r}) \ud\bs{r}
	+ \int F_{xc} \ud\bs{r} - \int \rho(\bs{r})v_{xc}(\bs{r}) \ud\bs{r}
\end{equation}
where it should be notet that
\begin{equation}
    E_{xc}[\rho] = \int F_{xc} \ud\bs{r} \neq \int \rho(\bs{r})v_{xc}(\bs{r}) \ud\bs{r}
\end{equation}

\section{Iterative solution algorithms}\label{sec:algorithms}
We will illustrate the iterative algorithms by looking at a simple one-electron system in which the 
electron is influenced only by a fixed nuclear potential $\hat{V} = v_{nuc}(\bs{r})$, which include 
the $H$ atom, the $He^+$ and $H_2^+$ ions or any other one-electron molecular ion within the 
Born-Oppenheimer approximation. Just as the Hartree-Fock and Kohn-Sham equations presented above, 
the electronic Scr\"{o}dinger equation is rewritten in integral form
\begin{align}
    \Big[-\frac{1}{2}\nabla^2 + \hat{V}\Big]\wavefunction(\bs{r}) &= E\wavefunction(\bs{r})\\
    \wavefunction(\bs{r})&=-2\int H^{\mu}(\bs{r}-\bs{r'})\hat{V}(\bs{r}')\wavefunction(\bs{r}')\ud\bs{r}'\\
    \label{eq:int_schr}
    \wavefunction &= -2 \hat{H}^{\mu}\Big[\hat{V}\wavefunction\Big]
\end{align}
with $\mu = \sqrt{-2E}$. This equation needs to be solved with respect to both the wave function
\wavefunction\ and the energy $E$.

\subsection{The power method}
Eq.~(\ref{eq:int_schr}) defines a fixed-point problem, and perhaps the simplest procedure to solve 
such a problem is the power method, where the operator is applied iteratively
\begin{align}
    \label{eq:power}
    \tilde{\wavefunction}^{n+1} &= -2 \hat{H}^{\mu^n}\Big[\hat{V}\wavefunction^n\Big]\\
    \wavefunction^{n+1} &= \frac{\tilde{\wavefunction}^{n+1}}{\|\tilde{\wavefunction}^{n+1}\|}
\end{align}
The tilde on the new wave function denotes that it is no longer normalized, 
as the operator $\hat{H}^{\mu}$ does not conserve the norm when the eigenvalue 
is not exact\cite{Kalos:1962}. The iteration label on the operator reflects the 
fact that the operator depends on the energy through $\mu^n = \sqrt{-2E^n}$ 
which needs to be updated in each iteration.

Such an iteration sequence $\boldsymbol{x}^{n+1} = \hat{O}(\boldsymbol{x}^n)$ will converge to 
the lowest energy eigenfunction of $\hat{O}$, provided that $\hat{O}$ defines a so-called 
contraction map. Schneider \etal\cite{Schneider:2008} proves linear convergence of the wave function 
and quadratic convergence of the energy for a simplified \emph{fixed} operator $\hat{O}$ (a 
general proof of the convergence of the Hartree-Fock and Kohn-Sham equations is yet to be found). 

\subsection{Energy calculation}
The energy of the wave function is formally calculated as the expectation value
\begin{equation}
    E = \frac{\langle\wavefunction| \hat{T} + \hat{V} | \wavefunction\rangle}
	{\langle\wavefunction|\wavefunction\rangle} 
\end{equation}
where $\hat{T}=-\nabla^2/2$ is the kinetic energy operator, and the potential energy operator 
in this case is the fixed nuclear potential $\hat{V} = v_{nuc}(\bs{r})$. As pointed out above, 
it is desirable to avoid the application of the kinetic operator, so following Harrison 
\etal\cite{Harrison_basic:2004} we exploit the fact that the Helmholtz operator is basically the 
inverse of the kinetic operator $2\hat{H}^{\mu} = (\hat{T} - E)^{-1}$, and extract the energy 
through the application of this operator. Given a wave function $\wavefunction^{n}$ and energy 
$E^{n}$ (this does not have to be the exact energy of $\wavefunction^{n}$, but it must be the 
energy used in $\mu^n=\sqrt{-2E^n}$ in the construction of the operator $\hat{H}^{\mu^n}$) at 
one iteration, we can calculate the (exact) energy $E^{n+1}$ of the wave function 
$\wavefunction^{n+1}$ at the next iteration as follows
\begin{align}
    \tilde{E}^{n+1}
    &=	\langle\tilde{\wavefunction}^{n+1}| \hat{T}+\hat{V} | \tilde{\wavefunction}^{n+1}\rangle\\
    &=	\langle\tilde{\wavefunction}^{n+1}|  \hat{T} - E^n  | \tilde{\wavefunction}^{n+1}\rangle
    +	\langle\tilde{\wavefunction}^{n+1}|  E^n + \hat{V}  | \tilde{\wavefunction}^{n+1}\rangle\\
    &=	\langle\tilde{\wavefunction}^{n+1}|  \hat{T} - E^n  | 
	    -2\hat{H}^{\mu^n}\big[\hat{V}\wavefunction^n\big]\rangle
    +	\langle\tilde{\wavefunction}^{n+1}| E^n + \hat{V} |\tilde{\wavefunction}^{n+1}\rangle\\
    &= -\langle\tilde{\wavefunction}^{n+1}| \hat{V} |\wavefunction^{n}\rangle
    +	\langle\tilde{\wavefunction}^{n+1}| E^n + \hat{V} |\tilde{\wavefunction}^{n+1}\rangle\\
    &= E^{n}\langle\tilde{\wavefunction}^{n+1}|\tilde{\wavefunction}^{n+1}\rangle + 
	\langle\tilde{\wavefunction}^{n+1}| \hat{V} |\Delta\tilde{\wavefunction}^{n}\rangle
\end{align}
where $\Delta \tilde{\wavefunction}^{n} \mydef \tilde{\wavefunction}^{n+1} - \wavefunction^{n}$.
Normalizing this expression gives the energy of $\wavefunction^{n+1}$, calculated directly from
the wave function update
\begin{align}
    E^{n+1} &= E^{n} + \Delta E^n\\
    \label{eq:energy_update}
    \Delta E^n &= 
	\frac{\langle\tilde{\wavefunction}^{n+1}| \hat{V} |\Delta\tilde{\wavefunction}^{n}\rangle}
	{\langle\tilde{\wavefunction}^{n+1}|\tilde{\wavefunction}^{n+1}\rangle}
\end{align}
without having to apply the kinetic energy operator, provided that the update comes directly 
from the application of the Helmholtz operator. For future reference, we also define the 
"normalized" wave function update 
\begin{equation}
    \label{eq:wavefunction_update}
    \Delta\wavefunction^n = \wavefunction^{n+1} - \wavefunction^n = 
	\frac{-2\hat{H}^{\mu^n}\big[\hat{V}\wavefunction^n\big]}{\|\tilde{\wavefunction}^{n+1}\|} 
	- \wavefunction^n
\end{equation}

\subsection{Krylov accelerated inexact Newton method}
The fixed-point problem in Eq.~(\ref{eq:int_schr}) can be viewed as finding 
the roots of the the following residual function
\begin{equation}
    f(\wavefunction) =  -2 \hat{H}^{\mu}\big[\hat{V}\wavefunction\big] - \wavefunction
\end{equation}
which can be done using Newton's method
\begin{align}
    \wavefunction^{n+1}	&= \wavefunction^n - \big[J(\wavefunction^n)\big]^{-1}f(\wavefunction^n)\\
    \label{eq:newton}
	&= \wavefunction^n - \big[J(\wavefunction^n)\big]^{-1}
	    \big(-2\hat{H}^{\mu^n}\big[\hat{V}\wavefunction^n\big] - \wavefunction^n\big)
\end{align}
where $J(\wavefunction^n)$ is the Jacobian. Comparing Eq.~(\ref{eq:newton}) with 
Eq.~(\ref{eq:power}), we can identify the power method as an \emph{inexact} 
Newton method where the Jacobian is approximated by $J(\wavefunction) \approx -1$.
Harrison\cite{Harrison_kain:2004} describes how to make use of the information in the
iterative history (Krylov subspace) to improve the approximation of the 
Jacobian in the Krylov accelerated inexact Newton (KAIN) method. The method 
is similar to the more commonly used direct inversion of iterative subspace 
(DIIS) method of Pulay\cite{Pulay:1980}, but while DIIS is looking for the best 
step within the iterative subspace, KAIN is using the same information to 
extrapolate to a step outside the iterative subspace and is thus considered 
superior to DIIS\cite{Harrison_kain:2004}.

Collecting the wave function and the energy into a vector $\bs{x} = (\wavefunction,E)$ we 
get the non-linear equation $f(\bs{x}) = \bs{0}$. At a given iteration $n$, we have the 
current approximation $\bs{x}^n = (\wavefunction^n,E^n)$ and the corresponding residual 
$f(\bs{x}^n) = (\Delta \wavefunction^n,\Delta E^n)$ defined through 
Eqs.~(\ref{eq:energy_update}) and (\ref{eq:wavefunction_update}). In the KAIN method the
new update $\delta\bs{x}^n$ is calculated in terms of the $m$ latest iterations
\begin{equation}
    \label{eq:KAIN_update}
    \delta \bs{x}^n = f(\bs{x}^n) + \sum_{j=1}^m c_j 
	\big[\left(\bs{x}^{j}-\bs{x}^{n}\right) + \left(f(\bs{x}^j)-f(\bs{x}^{n})\right)\big] 
\end{equation}
where the coefficients $c_j$ are obtained by solving the linear system $Ac=b$ 
\begin{align}
    A_{ij} &= \langle\bs{x}^n - \bs{x}^i|
		f(\bs{x}^n) - f(\bs{x}^j)\rangle\\
    b_{i}   &= \langle\bs{x}^n - \bs{x}^i | f(\bs{x}^n)\rangle
\end{align}
The size $m$ of the Krylov subspace is without constraints. The larger it is, 
the better is the Krylov update, but also the larger is the linear system. In 
general, the Krylov update will not conserve the norm of the orbital, so an 
additional normalization step should be added at this point.

\subsection{Algorithm for one-electron systems}
The single-orbital algorithm is quite straightforward. Starting from an arbitrary initial
guess for the wave function and the energy, the Helmholtz operator is applied once, the 
resulting wave function is normalized, and the correction $\Delta\wavefunction^n$ and the 
corresponding energy update $\Delta E^n$ is calculated as described above. Then the wave function
and energy are added to the KAIN history
\begin{equation}
    \bs{x}^n = \left(\wavefunction^n,E^n\right)\qquad \qquad
    f(\bs{x}^n) = \left(\Delta\wavefunction^n,\Delta E^n\right)
\end{equation}
If the length of the history exceeds some modest number the oldest vector is discarded. 
New updates are then calculated based on Eq.~(\ref{eq:KAIN_update})
\begin{equation}
    \delta \bs{x}^n = \left(\delta\wavefunction^n, \delta E^n\right)
\end{equation}
which are added to the previous guess, and the iteration is continued until the norm of the
wave function update (after the Helmholtz operator application) is below some threshold.
\begin{algorithm}
\begin{algorithmic}[1]
\STATE Given initial wave function $\wavefunction^0$ and energy $E^0$
\WHILE {$\varepsilon >$ threshold}
    \STATE Construct Helmholtz operator $\hat{H}^{\mu^n}$ using $\mu^n = \sqrt{-2E^n}$
    \STATE Multiply wave function $\wavefunction^n$ with potential
    \STATE Apply Helmholtz operator Eq.(\ref{eq:power}) and normalize
    \STATE Calculate wave function update $\Delta\wavefunction^n = \wavefunction^{n+1}-\wavefunction^n$
    \STATE Calculate wave function error $\varepsilon = \|\Delta\wavefunction^n\|$ 
    \STATE Calculate energy update $\Delta{E}^n$ from Eq.(\ref{eq:energy_update})
    \STATE Add $\big(\wavefunction^n, E^n\big)$ and $\big(\Delta\wavefunction^n,\Delta E^n\big)$
	    to KAIN history
    \STATE Calculate KAIN updates $\big(\delta\tilde{\wavefunction}^n,\delta{E}^n\big)$ from 
	    Eq.(\ref{eq:KAIN_update}) 
    \STATE Update wave function 
	    $\tilde{\wavefunction}^{n+1} = \wavefunction^n + \delta\tilde{\wavefunction}^n$
	    and normalize
    \STATE Update energy $E^{n+1} = E^n+\delta{E}^n$
\ENDWHILE
\label{alg:one-electron}
\caption{Iterative algorithm for the solution of the one-election Schr\"{o}dinger equation
    in its integral formulation.} 
\end{algorithmic}
\end{algorithm}

\subsection{Extension to many-electron systems}
There are a few important complications when the algorithm is extended to many-electron systems.
In the self-consistent field approximations we get systems of equations involving one-electron 
orbitals, like the canonical Kohn-Sham equations
\begin{equation}
    \orbital_i = -2 \hat{H}^{\mu_i}\Big[v_{eff}\orbital_i\Big]
\end{equation}
These equations can be solved in the same way as the one-electron Schr\"{o}dinger equation presented 
above, by iterating each equation separately. However, to avoid a collapse of all orbitals into the
lowest energy eigenfunction, orthogonality between the orbitals must be explicitly 
enforced\cite{Harrison_basic:2004}. There 
are many ways in which this can be achieved, but it is convenient to keep the canonical character of 
the orbitals throughout the optimization, by calculating and diagonalizing the Fock matrix in each 
iteration. The calculation of the Fock matrix 
\begin{equation}
    F_{ij} = \langle\orbital_i|\hat{T}+\hat{V}|\orbital_j\rangle
\end{equation}
can be done without the need to apply the kinetic energy operator by the same arguments as for 
the energy calculation of the one-electron wave function, but now the orbital dependence of the 
effective potential must be accounted for as well. Further complication arises in the KAIN solver, 
where all orbitals and energies are included in the Krylov vector
\begin{align}
    \bs{x}^n &= \left(\orbital_0^n,\cdots,\orbital_N^n,\epsilon_0^n,\cdots,\epsilon_N^n\right)\\
    f(\bs{x}^n) &= \left(\Delta\orbital_0^n,\cdots,\Delta\orbital_N^n,
	\Delta\epsilon_0^n,\cdots,\Delta\epsilon_N^n\right)
\end{align}
where it is important to keep track of the ordering of the orbitals throughout the iteration, 
especially in the case of degeneracies, where the orbitals are not uniquely defined. This is 
discussed further in publication III.

